import requests
from bs4 import BeautifulSoup
import csv

# URL de la page des offres d'emploi
URL = "https://jobmada.zohorecruit.com/jobs/Careers"

# En-t√™tes HTTP pour simuler un vrai navigateur
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# Envoyer une requ√™te GET √† Jobmada
response = requests.get(URL, headers=HEADERS)

# V√©rifier si la requ√™te a r√©ussi
if response.status_code == 200:
    # Parser le HTML avec BeautifulSoup
    soup = BeautifulSoup(response.text, "html.parser")

    # Trouver les blocs contenant les offres d'emploi
    job_list = soup.find_all("div", class_="posR")
    print(f"üîç {len(job_list)} offres d'emploi trouv√©es sur Jobmada")
    # Liste pour stocker les offres
    jobs = []

    for job in job_list:
        # R√©cup√©rer le titre du poste
        title = job.find("h3", class_="job-title").text.strip() if job.find("h3", class_="job-title") else "Non sp√©cifi√©"

        # R√©cup√©rer le nom de l'entreprise
        company = job.find("div", class_="company-name").text.strip() if job.find("div", class_="company-name") else "Non sp√©cifi√©"

        # R√©cup√©rer le lieu
        location = job.find("div", class_="job-location").text.strip() if job.find("div", class_="job-location") else "Non sp√©cifi√©"

        # R√©cup√©rer la date de publication
        date = job.find("div", class_="job-date").text.strip() if job.find("div", class_="job-date") else "Non sp√©cifi√©"

        # Ajouter les donn√©es dans la liste
        jobs.append([title, company, location, date])

    # Enregistrer les offres dans un fichier CSV
    with open("offres_emploi.csv", mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Titre du Poste", "Entreprise", "Lieu", "Date de Publication"])
        writer.writerows(jobs)

    print(f"‚úÖ {len(jobs)} offres d'emploi ont √©t√© enregistr√©es dans 'offres_emploi.csv'")

else:
    print("‚ùå Erreur lors de la r√©cup√©ration des donn√©es. V√©rifie l'URL ou ton r√©seau.")
